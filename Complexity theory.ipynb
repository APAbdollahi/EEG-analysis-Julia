{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ù***Important Note: This is a translation to Julia of Maryam Rahimi's code and text.***
    " In this module, EEG signals with standard electrode configuration of 19 spots on the head have been investigated.\n",
    " The focus of this piece of code will be in extracting meaningful measures from a network attributed to each person.\n",
    " This complex network will have measures such as betweenness, centrality, and clustering to name a few. \n",
    " \n",
    " The report consists of firstly reading the data, then, defining meaningful hypothetical edges between channels through both static and dynamic techniques, and then extracting measures from these networks. \n",
    " \n",
    " Finally, a t-test has been implemented to see if any meaningful difference exists between different age groups.\n",
    " Moreover, a very important measure called rewiring in the brain has been addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup: Installing Julia Packages\n",
    "\n",
    "Before running the rest of the notebook, you need to install the necessary Julia packages. Run the code cell below. This only needs to be done once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"EDF\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"Statistics\")\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"LinearAlgebra\")\n",
    "Pkg.add(\"MultipleTesting\")\n",
    "Pkg.add(\"HypothesisTests\")\n",
    "Pkg.add(\"DSP\")\n",
    "Pkg.add(\"Graphs\")\n",
    "Pkg.add(\"XLSX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading Files\n",
    "\n",
    "In this section of the code, we read the EDF (European Data format). Moreover, a static way to define a graph from the spatial distribution of channels is tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block reads an EDF file, extracts the first 20 signals, and organizes them into a matrix and a DataFrame.\n",
    "# - `EDF.jl` is used to read European Data Format files.\n",
    "# - `DataFrames.jl` provides the `DataFrame` type, similar to pandas.\n",
    "\n",
    "using EDF, DataFrames, Statistics, CSV\n",
    "\n",
    "# !!! IMPORTANT !!!\n",
    "# Update this path to point to your actual EDF file location.\n",
    "edf_filepath = \"path/to/your/file.edf\" \n",
    "\n",
    "# Make dt available outside the try block\n",
    "local dt \n",
    "try\n",
    "    edf_file = EDF.read(edf_filepath)\n",
    "\n",
    "    # Extract the first 20 channels into a matrix\n",
    "    num_channels = 20\n",
    "    num_samples = edf_file.signals[1].header.nsamples\n",
    "\n",
    "    # Pre-allocate a matrix to hold the signal data\n",
    "    global dt = Matrix{Float64}(undef, num_samples, num_channels)\n",
    "\n",
    "    for i in 1:num_channels\n",
    "        # Julia uses 1-based indexing\n",
    "        dt[:, i] = edf_file.signals[i].samples\n",
    "    end\n",
    "\n",
    "    # Convert the matrix to a DataFrame\n",
    "    df = DataFrame(dt, :auto)\n",
    "    println(\"Successfully read and processed the EDF file.\")\n",
    "    \n",
    "    # Display the first few rows of the DataFrame\n",
    "    first(df, 5)\n",
    "\n",
    "catch e\n",
    "    if isa(e, SystemError)\n",
    "        println(\"Error: Could not open the file at '$edf_filepath'. Please ensure the path is correct.\")\n",
    "    else\n",
    "        rethrow(e)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Complex Theory and Connectivity Definition (Static)\n",
    "\n",
    "In complexity theory, it is the correlation of different variables that matter to the analysis. Here, we calculate the correlation between channels and create a static adjacency matrix by applying a simple threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block computes a correlation matrix and then creates an adjacency matrix by applying a threshold.\n",
    "# - `Statistics.cor` computes the correlation matrix.\n",
    "# - Julia's broadcasting syntax `(corr_matrix .> 0.90)` is concise and efficient.\n",
    "# - `CSV.jl` is used for writing data to a CSV file.\n",
    "\n",
    "if @isdefined(dt)\n",
    "    # Calculate the correlation matrix from the data matrix `dt`\n",
    "    corr_matrix = cor(dt)\n",
    "\n",
    "    # Calculate the adjacency matrix using a threshold of 0.90\n",
    "    threshold = 0.90\n",
    "    adj_matrix = Int.(corr_matrix .> threshold)\n",
    "\n",
    "    # Convert the adjacency matrix to a DataFrame for saving\n",
    "    adj_df = DataFrame(adj_matrix, :auto)\n",
    "\n",
    "    # Export the adjacency matrix to a CSV file\n",
    "    output_path = \"testadj.csv\"\n",
    "    CSV.write(output_path, adj_df)\n",
    "    println(\"Adjacency matrix saved to '$output_path'\")\n",
    "else\n",
    "    println(\"Skipping connectivity definition because the EDF file was not loaded.\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Partial Correlation\n",
    "\n",
    "In the following, we define another form of connectivity between different hypothetical nodes in the brain using partial correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block defines the `partial_corr` function.\n",
    "# - `LinearAlgebra.jl` provides matrix operations. The backslash operator `\\` is used\n",
    "#   for solving linear least-squares problems.\n",
    "# - `Statistics.cor` is used for the Pearson correlation of the residuals.\n",
    "\n",
    "using LinearAlgebra, Statistics\n",
    "\n",
    "\"\"\"\n",
    "    partial_corr(C::AbstractMatrix)\n",
    "\n",
    "Returns the sample linear partial correlation coefficients between pairs of variables in C,\n",
    "controlling for the remaining variables in C.\n",
    "\n",
    "# Arguments\n",
    "- `C`: An n x p matrix where each column is a variable.\n",
    "\n",
    "# Returns\n",
    "- `P_corr`: A p x p matrix where `P_corr[i, j]` contains the partial correlation\n",
    "            of `C[:, i]` and `C[:, j]`.\n",
    "\"\"\"\n",
    "function partial_corr(C::AbstractMatrix)\n",
    "    n, p = size(C)\n",
    "    P_corr = zeros(Float64, p, p)\n",
    "\n",
    "    for i in 1:p\n",
    "        P_corr[i, i] = 1\n",
    "        for j in (i+1):p\n",
    "            # Create an index for all columns except i and j\n",
    "            idx = trues(p)\n",
    "            idx[i] = false\n",
    "            idx[j] = false\n",
    "\n",
    "            # Perform linear regression to get residuals\n",
    "            beta_i = C[:, idx] \\ C[:, j]\n",
    "            res_j = C[:, j] - C[:, idx] * beta_i\n",
    "\n",
    "            beta_j = C[:, idx] \\ C[:, i]\n",
    "            res_i = C[:, i] - C[:, idx] * beta_j\n",
    "\n",
    "            # Calculate Pearson correlation between the residuals\n",
    "            corr_val = cor(res_i, res_j)\n",
    "            P_corr[i, j] = corr_val\n",
    "            P_corr[j, i] = corr_val\n",
    "        end\n",
    "    end\n",
    "    return P_corr\n",
    "end\n",
    "\n",
    "# Example Usage:\n",
    "test_data = rand(100, 5)\n",
    "pcorr_matrix = partial_corr(test_data)\n",
    "println(\"Example partial correlation matrix:\")\n",
    "pcorr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Dynamic Definition of the Network\n",
    "\n",
    "Instead of only imposing a static correlation threshold, we can use a Bonferroni-adjusted statistical test to define edges for our network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block demonstrates multiple testing correction and calculating Pearson's R with p-values.\n",
    "# - `MultipleTesting.jl` is the Julia equivalent of parts of `statsmodels.multicomp`.\n",
    "# - `HypothesisTests.jl` provides functions for statistical tests, including `CorrelationTest`.\n",
    "\n",
    "using MultipleTesting, HypothesisTests, DataFrames\n",
    "\n",
    "# --- Part 1: Bonferroni Correction ---\n",
    "# Example p-value matrix (in a real case, these would be derived from your correlations)\n",
    "p_values_matrix = rand(10, 10)\n",
    "\n",
    "# The `adjust` function expects a vector of p-values.\n",
    "p_adjusted = adjust(vec(p_values_matrix), Bonferroni())\n",
    "p_adjusted_matrix = reshape(p_adjusted, 10, 10)\n",
    "\n",
    "# To get a boolean matrix of significant connections:\n",
    "alpha = 0.05\n",
    "significant_connections = p_adjusted_matrix .< alpha\n",
    "println(\"Significant connections after Bonferroni correction:\")\n",
    "display(significant_connections)\n",
    "\n",
    "# --- Part 2: Pearson Correlation with P-value ---\n",
    "df_pearson_example = DataFrame(\"list 1\" => [2, 4, 6, 8], \"list 2\" => [4, 16, 36, 64])\n",
    "\n",
    "# Perform a correlation test\n",
    "test = CorrelationTest(df_pearson_example[!, \"list 1\"], df_pearson_example[!, \"list 2\"])\n",
    "\n",
    "# Extract the coefficient and p-value\n",
    "pearson_coef = test.cor\n",
    "p_val = pvalue(test)\n",
    "\n",
    "println(\"\\nPearson Correlation Coefficient: \", pearson_coef, \" and a P-value of: \", p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Decomposition, Network Measures, and Significance\n",
    "\n",
    "In the following, the brain signals are decomposed into their frequency bands (Delta, theta, alpha, beta, etc.). Then, for each band, we construct a network and compute a variety of measures.\n",
    "\n",
    "These measures can then be used to study aging and detect brain diseases. This final block combines all the previous steps into a full analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DSP, Statistics, MultipleTesting, Graphs, LinearAlgebra, DataFrames, XLSX\n",
    "\n",
    "# Helper function to calculate average shortest path length, ignoring disconnected pairs.\n",
    "function mean_shortest_path(g)\n",
    "    dists = gdistances(g)\n",
    "    valid_paths = filter(d -> d > 0 && d != typemax(Int), dists)\n",
    "    return isempty(valid_paths) ? 0.0 : mean(valid_paths)\n",
    "end\n",
    "\n",
    "function main_analysis()\n",
    "    # !!! IMPORTANT !!!\n",
    "    # Configure your input and output paths here\n",
    "    directory = \"path/to/your/data/folder/\" \n",
    "    output_dir = \"results/delta\"\n",
    "    mkpath(output_dir) # Create output directory if it doesn't exist\n",
    "\n",
    "    files = isdir(directory) ? readdir(directory) : []\n",
    "    if isempty(files)\n",
    "        println(\"Warning: Directory not found or is empty: '$directory'. Aborting analysis.\")\n",
    "        return\n",
    "    end\n",
    "\n",
    "    # Pre-allocate a DataFrame to store results\n",
    "    results_df = DataFrame(\n",
    "        Name = String[],\n",
    "        GlobalEfficiency = Float64[],\n",
    "        AvgClustering = Float64[],\n",
    "        AvgShortestPath = Float64[],\n",
    "        MaxBetweenness = Float64[],\n",
    "        Diameter = Int[],\n",
    "        Energy = Float64[],\n",
    "        MeanDegree = Float64[]\n",
    "    )\n",
    "\n",
    "    for file in files\n",
    "        println(\"Processing: $file\")\n",
    "        filepath = joinpath(directory, file)\n",
    "\n",
    "        # 1. Read and reshape data\n",
    "        raw_data = open(filepath) do f\n",
    "            read(f, Vector{Float32})\n",
    "        end\n",
    "        trimmed_length = length(raw_data) - (length(raw_data) % 310)\n",
    "        a = reshape(raw_data[1:trimmed_length], (310, :))\n",
    "\n",
    "        # 2. Filter for frequency bands (Delta band: 0.1-4 Hz)\n",
    "        fs = 250 # Sampling frequency\n",
    "        responsetype = Bandpass(0.1, 4, fs=fs)\n",
    "        designmethod = Butterworth(5)\n",
    "        filter_coeffs = digitalfilter(responsetype, designmethod)\n",
    "        freq_bands_all = filt(filter_coeffs, a, dims=2)\n",
    "        freq_bands = freq_bands_all[3:3:307, :]\n",
    "\n",
    "        # 3. Create Network\n",
    "        corr_mat = cor(freq_bands')\n",
    "        alpha = 0.05\n",
    "        p_adjusted_vec = adjust(vec(abs.(corr_mat)), Bonferroni())\n",
    "        adj_bool_mat = reshape(p_adjusted_vec .< alpha, size(corr_mat))\n",
    "        adj_mat = Int.(Symmetric(adj_bool_mat))\n",
    "        adj_mat[diagind(adj_mat)] .= 0\n",
    "\n",
    "        # 4. Calculate Graph Measures\n",
    "        G = Graph(adj_mat)\n",
    "        if nv(G) > 0\n",
    "            eff = global_efficiency(G)\n",
    "            clu = mean(local_clustering_coefficient(G))\n",
    "            spl = mean_shortest_path(G)\n",
    "            bc = betweenness_centrality(G)\n",
    "            bcm = isempty(bc) ? 0.0 : maximum(bc)\n",
    "            diam = diameter(G)\n",
    "            w, _ = eigen(adj_mat)\n",
    "            energy = sum(abs.(w))\n",
    "            deg = mean(degree(G))\n",
    "            push!(results_df, (file, eff, clu, spl, bcm, diam, energy, deg))\n",
    "        else\n",
    "            push!(results_df, (file, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # 5. Save results to an Excel file\n",
    "    output_excel_path = joinpath(output_dir, \"delta_measures.xlsx\")\n",
    "    XLSX.writetable(output_excel_path, results_df, overwrite=true, sheetname=\"delta\")\n",
    "    println(\"Analysis complete. Results saved to '$output_excel_path'\")\n",
    "    \n",
    "    return results_df\n",
    "end\n",
    "\n",
    "# Run the main analysis function\n",
    "# final_results = main_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
